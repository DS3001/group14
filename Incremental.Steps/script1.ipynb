{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSS7218_R3.sav file has been converted to GSS2018.csv.\n",
      "Current Working Directory: c:\\Users\\qaism\\Downloads\\2018_spss\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the SAV file into a Pandas DataFrame\n",
    "data, meta = pyreadstat.read_sav('GSS2018.sav')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "data.to_csv('GSS2018.csv', index=False)\n",
    "\n",
    "print(\"GSS7218_R3.sav file has been converted to GSS2018.csv.\")\n",
    "\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== General Information =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2348 entries, 0 to 2347\n",
      "Columns: 1065 entries, ABANY to ZODIAC\n",
      "dtypes: float64(1065)\n",
      "memory usage: 19.1 MB\n",
      "\n",
      "===== Shape of Dataset =====\n",
      "Number of Rows: 2348\n",
      "Number of Columns: 1065\n",
      "\n",
      "===== Missing Values Count (Top 10) =====\n",
      "AWAY7      2347\n",
      "WHERE7     2347\n",
      "AWAY5      2346\n",
      "MHP5R2     2346\n",
      "AWAY6      2346\n",
      "RELSP10    2346\n",
      "MAR9       2346\n",
      "OLD10      2346\n",
      "MHP3R2     2346\n",
      "MHP4R2     2346\n",
      "dtype: int64\n",
      "\n",
      "===== Unique Values Count (Top 10) =====\n",
      "ID           2348\n",
      "WTSSNR        399\n",
      "OCC10         381\n",
      "PAOCC10       321\n",
      "SEI10INC      304\n",
      "SEI10EDUC     298\n",
      "SPOCC10       297\n",
      "SEI10         295\n",
      "ISCO08        275\n",
      "PASEI10       270\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('GSS2018.csv')\n",
    "\n",
    "# Display general information about the dataset\n",
    "print(\"===== General Information =====\")\n",
    "df.info()\n",
    "# Display the shape of the dataset\n",
    "print(\"\\n===== Shape of Dataset =====\")\n",
    "print(f\"Number of Rows: {df.shape[0]}\")\n",
    "print(f\"Number of Columns: {df.shape[1]}\")\n",
    "# Display the number of missing values in each column\n",
    "print(\"\\n===== Missing Values Count (Top 10) =====\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# Display the number of unique values in each column\n",
    "print(\"\\n===== Unique Values Count (Top 10) =====\")\n",
    "print(df.nunique().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Column_Name                                         Definition\n",
      "0       ABANY  ABORTION IF W OMAN W ANTS FOR ANY REASON\\nPage...\n",
      "1    ABDEFECT                    STRONG CHANCE OF SERIOUS DEFECT\n",
      "2    ABFELEGL  W OMEN ONLY: W OMEN SHOULD BE ABLE TO HAVE LEG...\n",
      "3     ABHELP1                                          Not Found\n",
      "4     ABHELP2            R W OULD HELP W ITH PAYING FOR ABORTION\n",
      "5     ABHELP3  R W OULD HELP W ITH PAYING FOR ABORTION-RELATE...\n",
      "6     ABHELP4  R W OULD HELP W ITH EMOTIONAL SUPPORT FOR ABOR...\n",
      "7      ABHLTH               W OMAN'S HEALTH SERIOUSLY ENDANGERED\n",
      "8    ABINSPAY                                          Not Found\n",
      "9   ABMEDGOV1  W OMAN AND DOCTOR OR GOVT SHOULD DECIDE W HAT ...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file containing the column definitions\n",
    "json_file_path = r'C:\\Users\\qaism\\OneDrive - University of Virginia\\Documents\\GitHub\\group14\\GSS_Codebook_index.json'\n",
    "with open(json_file_path, 'r') as f:\n",
    "    column_definitions_from_json = json.load(f)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('GSS2018.csv')  # Adjust this path as needed\n",
    "\n",
    "# Create a DataFrame to match columns in the dataset with their definitions from the JSON file\n",
    "column_match_df_from_json = pd.DataFrame({\n",
    "    'Column_Name': df.columns,\n",
    "    'Definition': [column_definitions_from_json.get(col, 'Not Found') for col in df.columns]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(column_match_df_from_json.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RELIG  CHILDS  AGEKDBRN  EDUC  HAPPY  ATTEND  GOD  INCOME  FAMGEN   AGE  \\\n",
      "0   11.0     0.0       NaN  14.0    2.0     5.0  6.0     NaN     1.0  43.0   \n",
      "1    2.0     3.0      21.0  10.0    1.0     2.0  6.0    12.0     2.0  74.0   \n",
      "2    4.0     2.0      35.0  16.0    1.0     2.0  5.0    12.0     2.0  42.0   \n",
      "3    1.0     2.0      32.0  16.0    1.0     6.0  6.0     NaN     1.0  63.0   \n",
      "4    2.0     0.0       NaN  18.0    2.0     8.0  6.0     NaN     1.0  71.0   \n",
      "\n",
      "   SEX  RACE  \n",
      "0  1.0   1.0  \n",
      "1  2.0   1.0  \n",
      "2  1.0   1.0  \n",
      "3  2.0   1.0  \n",
      "4  1.0   2.0  \n"
     ]
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "df = pd.read_csv('GSS2018.csv')  # Adjust the path as needed\n",
    "\n",
    "# List of variables of interest\n",
    "variables_of_interest = ['RELIG', 'CHILDS', 'AGEKDBRN', 'EDUC', 'HAPPY', 'ATTEND', 'GOD', 'INCOME', 'FAMGEN']\n",
    "\n",
    "# Additional potentially important demographic columns\n",
    "additional_columns = ['AGE', 'SEX', 'RACE']\n",
    "\n",
    "# Combine both lists to get all columns to keep\n",
    "all_columns_to_keep = variables_of_interest + additional_columns\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "df_selected = df[all_columns_to_keep]\n",
    "\n",
    "# Show the first few rows of the new DataFrame to verify\n",
    "print(df_selected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Column_Name                                 Definition\n",
      "28          AGE                          AGE OF RESPONDENT\n",
      "30     AGEKDBRN               R'S AGE W HEN 1ST CHILD BORN\n",
      "36       ATTEND    HOW  OFTEN R ATTENDS RELIGIOUS SERVICES\n",
      "73       CHILDS                         NUMBER OF CHILDREN\n",
      "199        EDUC           HIGHEST YEAR OF SCHOOL COMPLETED\n",
      "232      FAMGEN  NUMBER OF FAMILY GENERATIONS IN HOUSEHOLD\n",
      "283         GOD     R'S CONFIDENCE IN THE EXISTENCE OF GOD\n",
      "297       HAPPY                          GENERAL HAPPINESS\n",
      "370      INCOME                        TOTAL FAMILY INCOME\n",
      "709        RACE                         RACE OF RESPONDENT\n",
      "768       RELIG                   R'S RELIGIOUS PREFERENCE\n",
      "853         SEX                            RESPONDENTS SEX\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame to match only the columns present in df_selected with their definitions from the JSON file\n",
    "df_selected_definitions = column_match_df_from_json[column_match_df_from_json['Column_Name'].isin(df_selected.columns)]\n",
    "\n",
    "# Remove any definitions from the JSON that are not found in df_selected\n",
    "df_selected_definitions = df_selected_definitions[df_selected_definitions['Definition'] != 'Not Found']\n",
    "\n",
    "# Display the DataFrame with selected column definitions\n",
    "print(df_selected_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RELIG  CHILDS  AGEKDBRN  EDUC  HAPPY  ATTEND  GOD  INCOME  FAMGEN   AGE  \\\n",
      "0   11.0     0.0       NaN  14.0    2.0     5.0  6.0     NaN     1.0  43.0   \n",
      "1    2.0     3.0      21.0  10.0    1.0     2.0  6.0    12.0     2.0  74.0   \n",
      "2    4.0     2.0      35.0  16.0    1.0     2.0  5.0    12.0     2.0  42.0   \n",
      "3    1.0     2.0      32.0  16.0    1.0     6.0  6.0     NaN     1.0  63.0   \n",
      "4    2.0     0.0       NaN  18.0    2.0     8.0  6.0     NaN     1.0  71.0   \n",
      "\n",
      "   SEX  RACE  MARITAL  POLVIEWS  HRS1  \n",
      "0  1.0   1.0      5.0       6.0   NaN  \n",
      "1  2.0   1.0      4.0       NaN   NaN  \n",
      "2  1.0   1.0      1.0       5.0  40.0  \n",
      "3  2.0   1.0      1.0       4.0  40.0  \n",
      "4  1.0   2.0      3.0       7.0   NaN  \n"
     ]
    }
   ],
   "source": [
    "# List of additional important columns that are verified to be in the original CSV\n",
    "verified_additional_important_columns = ['MARITAL', 'POLVIEWS', 'HRS1']\n",
    "\n",
    "# Update the list of all columns to keep with verified columns\n",
    "all_columns_to_keep_updated = all_columns_to_keep + verified_additional_important_columns\n",
    "\n",
    "df_selected_updated = df[all_columns_to_keep_updated]\n",
    "print(df_selected_updated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RELIG  CHILDS  AGEKDBRN  EDUC  HAPPY  ATTEND  GOD  INCOME  FAMGEN   AGE  \\\n",
      "0  11.0     0.0       NaN  14.0    2.0     5.0  6.0     NaN     1.0  43.0   \n",
      "1   2.0     3.0      21.0  10.0    1.0     2.0  6.0    12.0     2.0  74.0   \n",
      "2   4.0     2.0      35.0  16.0    1.0     2.0  5.0    12.0     2.0  42.0   \n",
      "3   1.0     2.0      32.0  16.0    1.0     6.0  6.0     NaN     1.0  63.0   \n",
      "4   2.0     0.0       NaN  18.0    2.0     8.0  6.0     NaN     1.0  71.0   \n",
      "\n",
      "   SEX  RACE  MARITAL  POLVIEWS  HRS1  \n",
      "0  1.0   1.0      5.0       6.0   NaN  \n",
      "1  2.0   1.0      4.0       NaN   NaN  \n",
      "2  1.0   1.0      1.0       5.0  40.0  \n",
      "3  2.0   1.0      1.0       4.0  40.0  \n",
      "4  1.0   2.0      3.0       7.0   NaN  \n"
     ]
    }
   ],
   "source": [
    "# Convert data types where needed using .loc[]\n",
    "df_selected_updated.loc[:, 'INCOME'] = pd.to_numeric(df_selected_updated['INCOME'], errors='coerce')\n",
    "\n",
    "# Handle outliers: for demonstration, capping 'AGE' at 100\n",
    "df_selected_updated.loc[:, 'AGE'] = df_selected_updated['AGE'].apply(lambda x: min(x, 100))\n",
    "\n",
    "# Normalize text data: for demonstration, converting 'RELIG' to uppercase\n",
    "df_selected_updated.loc[:, 'RELIG'] = df_selected_updated['RELIG'].astype(str).str.upper()\n",
    "\n",
    "# Drop rows with more than 3 missing values\n",
    "df_cleaned = df_selected_updated.dropna(thresh=len(df_selected_updated.columns) - 3)\n",
    "\n",
    "# Show the first few rows of the cleaned DataFrame to verify\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('C:\\\\Users\\\\qaism\\\\OneDrive - University of Virginia\\\\Documents\\\\GitHub\\\\group14\\\\df_cleaned.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
